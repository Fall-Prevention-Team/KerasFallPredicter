Modification,precision,accuracy,recall,duration
Original,0.9404336734693878,0.9457364341085271,0.9440586419753086,136.20911478996277
Kernel_size,0.9381598793363499,0.9457364341085271,0.9483024691358024,133.4198203086853
Conv1D_module_layers_6,0.9293206793206793,0.937984496124031,0.9421296296296297,207.01896619796753
Activation_leaky_relu,0.9219457013574661,0.9302325581395349,0.931712962962963,131.71287298202515
Monitor_val_loss,0.948015873015873,0.9457364341085271,0.935570987654321,128.52588748931885
Patience_100,0.9310126582278482,0.937984496124031,0.9378858024691358,132.68702912330627
Dataset_robust,0.8726495726495727,0.8926174496644296,0.8726495726495727,173.08200430870056
Dataset_standard,0.9044871794871795,0.9194630872483222,0.9044871794871795,172.10048174858093
Kernel_size+Conv1D_module_layers_6,0.9372708224201153,0.937984496124031,0.9293981481481481,193.86624193191528
Kernel_size+Conv1D_module_layers_6+Activation_leaky_relu,0.9436948624805397,0.9457364341085271,0.9398148148148148,205.88953852653503
Kernel_size+Conv1D_module_layers_6+Activation_leaky_relu+monitor_val_loss,0.9293206793206793,0.937984496124031,0.9421296296296297,188.59424662590027
Kernel_size+Activation_leaky_relu,0.9310126582278482,0.937984496124031,0.9378858024691358,131.87724494934082
Kernel_size+Activation_leaky_relu+monitor_val_loss,0.9368172790466733,0.9457364341085271,0.9525462962962963,129.6422836780548
Kernel_size+Monitor_val_loss+Patience,0.9310126582278482,0.937984496124031,0.9378858024691358,131.18997931480408
Monitor_val_loss+Patience,0.9170524691358024,0.9224806201550387,0.9170524691358024,127.5204336643219
